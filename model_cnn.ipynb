{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.io import read_image\n",
    "from torchsummary import summary\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device=\"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.info = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.info)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.info.imgPath.values[idx]\n",
    "        label = self.info['class'].values[idx]\n",
    "        image = read_image(path, mode=torchvision.io.image.ImageReadMode.RGB).float()\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   patient  class  posX  posY                                         imgPath\n",
      "0    12954      0  1151  1401  data/12954/0/12954_idx5_x1151_y1401_class0.png\n",
      "1    12954      0  1951  2901  data/12954/0/12954_idx5_x1951_y2901_class0.png\n",
      "2    12954      0   151   501    data/12954/0/12954_idx5_x151_y501_class0.png\n",
      "3    12954      0  1701  2251  data/12954/0/12954_idx5_x1701_y2251_class0.png\n",
      "4    12954      0  1501  2001  data/12954/0/12954_idx5_x1501_y2001_class0.png\n",
      "Number of Unique Patients:  279\n",
      "   patient  class  posX  posY                                         imgPath\n",
      "0    12954      0  1151  1401  data/12954/0/12954_idx5_x1151_y1401_class0.png\n",
      "1    12954      0  1951  2901  data/12954/0/12954_idx5_x1951_y2901_class0.png\n",
      "2    12954      0   151   501    data/12954/0/12954_idx5_x151_y501_class0.png\n",
      "3    12954      0  1701  2251  data/12954/0/12954_idx5_x1701_y2251_class0.png\n",
      "4    12954      0  1501  2001  data/12954/0/12954_idx5_x1501_y2001_class0.png\n",
      "Number of Train Patients:  195\n",
      "      patient  class  posX  posY  \\\n",
      "6566    15634      0  2401  1801   \n",
      "6567    15634      0  1001  1651   \n",
      "6568    15634      0  2051  1351   \n",
      "6569    15634      0  1301  2201   \n",
      "6570    15634      0  1351  1301   \n",
      "\n",
      "                                             imgPath  \n",
      "6566  data/15634/0/15634_idx5_x2401_y1801_class0.png  \n",
      "6567  data/15634/0/15634_idx5_x1001_y1651_class0.png  \n",
      "6568  data/15634/0/15634_idx5_x2051_y1351_class0.png  \n",
      "6569  data/15634/0/15634_idx5_x1301_y2201_class0.png  \n",
      "6570  data/15634/0/15634_idx5_x1351_y1301_class0.png  \n",
      "Number of Validation Patients:  42\n",
      "      patient  class  posX  posY  \\\n",
      "7926    13687      0  2251   251   \n",
      "7927    13687      0  2801   751   \n",
      "7928    13687      0  1551   701   \n",
      "7929    13687      0  1251   651   \n",
      "7930    13687      0  2851  1251   \n",
      "\n",
      "                                             imgPath  \n",
      "7926   data/13687/0/13687_idx5_x2251_y251_class0.png  \n",
      "7927   data/13687/0/13687_idx5_x2801_y751_class0.png  \n",
      "7928   data/13687/0/13687_idx5_x1551_y701_class0.png  \n",
      "7929   data/13687/0/13687_idx5_x1251_y651_class0.png  \n",
      "7930  data/13687/0/13687_idx5_x2851_y1251_class0.png  \n",
      "Number of Test Patients:  42\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv(\"breastCancerDataframe.csv\", index_col=0)\n",
    "print(df.head())\n",
    "\n",
    "patientIDs = df.patient.unique()\n",
    "print(\"Number of Unique Patients: \", len(patientIDs))\n",
    "\n",
    "patients_train, temp = train_test_split(patientIDs, test_size=0.3, random_state=42)\n",
    "patients_val, patients_test = train_test_split(temp, test_size=0.5, random_state=42)\n",
    "\n",
    "df_train = df.loc[df['patient'].isin(patients_train)]\n",
    "print(df_train.head())\n",
    "print(\"Number of Train Patients: \", df_train.patient.nunique())\n",
    "\n",
    "df_val = df.loc[df['patient'].isin(patients_val)]\n",
    "print(df_val.head())\n",
    "print(\"Number of Validation Patients: \", df_val.patient.nunique())\n",
    "\n",
    "df_test = df.loc[df['patient'].isin(patients_test)]\n",
    "print(df_test.head())\n",
    "print(\"Number of Test Patients: \", df_test.patient.nunique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        #transforms.RandomRotation(45),\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "train_dataset = CustomImageDataset(df_train, transform=transform)\n",
    "val_dataset = CustomImageDataset(df_val, transform=transform)\n",
    "test_dataset = CustomImageDataset(df_test, transform=transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nmodel=models.resnet18(pretrained=True)\\nprint(model)\\n\\nmodel.fc = nn.Sequential(\\n    nn.Linear(model.fc.in_features, 512),\\n    nn.ReLU(),\\n    nn.BatchNorm1d(512),\\n    nn.Dropout(0.5),\\n\\n    nn.Linear(512, 256),\\n    nn.ReLU(),\\n    nn.BatchNorm1d(256),\\n    nn.Dropout(0.5),\\n\\n    nn.Linear(256, 1))\\n\\ndef init_weights(m):\\n    if type(m) == nn.Linear:\\n        torch.nn.init.xavier_uniform_(m.weight)\\n        m.bias.data.fill_(0.01)\\n\\nmodel.apply(init_weights)\\n'"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "model=models.resnet18(pretrained=True)\n",
    "print(model)\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(model.fc.in_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.Dropout(0.5),\n",
    "\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.Dropout(0.5),\n",
    "\n",
    "    nn.Linear(256, 1))\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "EfficientNet(\n  (features): Sequential(\n    (0): ConvNormActivation(\n      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): SiLU(inplace=True)\n    )\n    (1): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (2): ConvNormActivation(\n            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n      )\n    )\n    (2): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): ConvNormActivation(\n            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): ConvNormActivation(\n            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n      )\n    )\n    (3): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): ConvNormActivation(\n            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): ConvNormActivation(\n            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n      )\n    )\n    (4): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): ConvNormActivation(\n            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): ConvNormActivation(\n            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): ConvNormActivation(\n            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n      )\n    )\n    (5): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): ConvNormActivation(\n            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): ConvNormActivation(\n            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): ConvNormActivation(\n            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n      )\n    )\n    (6): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): ConvNormActivation(\n            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): ConvNormActivation(\n            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): ConvNormActivation(\n            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n      )\n      (3): MBConv(\n        (block): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): ConvNormActivation(\n            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n      )\n    )\n    (7): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): ConvNormActivation(\n            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n      )\n    )\n    (8): ConvNormActivation(\n      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): SiLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=1)\n  (classifier): Sequential(\n    (0): Dropout(p=0.2, inplace=False)\n    (1): Linear(in_features=1280, out_features=512, bias=True)\n    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): ReLU()\n    (4): Dropout(p=0.2, inplace=False)\n    (5): Linear(in_features=512, out_features=256, bias=True)\n    (6): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): ReLU()\n    (8): Linear(in_features=256, out_features=1, bias=True)\n  )\n)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.efficientnet_b0(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(1280, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Linear(256, 1))\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "model.apply(init_weights)\n",
    "#summary(model, (3,224,224))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Calculate performance measures\n",
    "def compute_performance(yhat, y, pos_cutoff):\n",
    "\n",
    "    # First, get tp, tn, fp, fn\n",
    "    tp = sum(np.logical_and(yhat >= pos_cutoff, y == 1).numpy())\n",
    "    tn = sum(np.logical_and(yhat < pos_cutoff, y == 0).numpy())\n",
    "    fp = sum(np.logical_and(yhat >= pos_cutoff, y == 0).numpy())\n",
    "    fn = sum(np.logical_and(yhat < pos_cutoff, y == 1).numpy())\n",
    "\n",
    "    print(f\"tp: {tp} tn: {tn} fp: {fp} fn: {fn}\")\n",
    "\n",
    "    # Accuracy\n",
    "    #acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "    # Precision\n",
    "    # \"Of the ones I labeled +, how many are actually +?\"\n",
    "    precision = tp / (tp + fp)\n",
    "\n",
    "    # Recall\n",
    "    # \"Of all the + in the data, how many do I correctly label?\"\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    # Sensitivity\n",
    "    # \"Of all the + in the data, how many do I correctly label?\"\n",
    "    sensitivity = recall\n",
    "\n",
    "    # Specificity\n",
    "    # \"Of all the - in the data, how many do I correctly label?\"\n",
    "    specificity = tn / (fp + tn)\n",
    "\n",
    "    balanced_acc = 0.5*(sensitivity+specificity)\n",
    "    #fMeasure =  2*((precision*recall)/(precision+recall))\n",
    "\n",
    "    auroc = roc_auc_score(y, yhat)\n",
    "\n",
    "    # Print results\n",
    "    print(\"Balanced Accuracy: \", balanced_acc,\" Specificity: \",specificity,\" AUROC Score: \", auroc,\n",
    "          \" Sensitivity: \",sensitivity,\" Precision: \",precision,)\n",
    "\n",
    "def train(model, dataloader_train, dataloader_val, device='cpu', epochs=10, early_stop=2, lr=0.001, verbose=True):\n",
    "\n",
    "    opt = torch.optim.Adam(model.classifier.parameters(), lr=lr)\n",
    "    #opt = torch.optim.Adam(model.fc.parameters(), lr=lr)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    lowest_val_loss, train_loss = np.inf, 0\n",
    "    lowest_val_epoch = 0\n",
    "    epochs_wo_improvement = 0\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    train_losses, val_losses=[], []\n",
    "\n",
    "    for e in range(epochs):\n",
    "        epoch_train_loss = 0\n",
    "        epoch_val_loss = 0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for inputs, targets in tqdm(dataloader_train):\n",
    "\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            model.zero_grad(set_to_none=True)\n",
    "\n",
    "            output = model.forward(inputs)\n",
    "            loss = criterion(output.squeeze(), targets.float())\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            epoch_train_loss+=loss\n",
    "\n",
    "        epoch_train_loss = epoch_train_loss.item()/((len(dataloader_train.dataset)%BATCH_SIZE)*BATCH_SIZE)\n",
    "\n",
    "        train_losses.append(epoch_train_loss)\n",
    "\n",
    "        #VALIDATION\n",
    "\n",
    "        model.eval()\n",
    "        val_preds, val_targets_list = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in tqdm(dataloader_val):\n",
    "\n",
    "                val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "\n",
    "                model.zero_grad(set_to_none=True)\n",
    "\n",
    "                val_output = model.forward(val_inputs).squeeze()\n",
    "                val_preds+=val_output\n",
    "                val_targets_list+=val_targets\n",
    "\n",
    "                epoch_val_loss += criterion(val_output, val_targets.float())\n",
    "\n",
    "            epoch_val_loss = epoch_val_loss.item()/((len(dataloader_val.dataset)%BATCH_SIZE)*BATCH_SIZE)\n",
    "            val_losses.append(epoch_val_loss)\n",
    "\n",
    "            compute_performance(torch.sigmoid(torch.Tensor(val_preds)), torch.Tensor(val_targets_list), 0.5)\n",
    "\n",
    "        if epoch_val_loss <= lowest_val_loss:\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            lowest_val_loss = epoch_val_loss\n",
    "            train_loss=epoch_train_loss\n",
    "            lowest_val_epoch=e\n",
    "            epochs_wo_improvement=0\n",
    "        else:\n",
    "            epochs_wo_improvement+=1\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Epoch: {}/{}...\".format(e, epochs), \"Loss: {:.4f}...\".format(epoch_train_loss), \"Val Loss: {:.4f}\".format(epoch_val_loss),)\n",
    "\n",
    "        #early stopping\n",
    "        if epochs_wo_improvement>=early_stop:\n",
    "            if verbose:\n",
    "                print(\"Early Stop no improvement in validation loss in \"+str(early_stop)+\" validation steps\")\n",
    "            break\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nLowest Validation Loss: \"+str(lowest_val_loss)+\" at epoch \"+str(lowest_val_epoch)+'\\n')\n",
    "\n",
    "    model.load_state_dict(best_model)\n",
    "\n",
    "    run_ID = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "    torch.save({'model_state_dict': best_model}, './BestModels/'+str(run_ID)+'_E_'+str(lowest_val_epoch)+'_TL_'+str(round(train_loss, 4))+'_VL_'+str(round(lowest_val_loss, 4))+'.pt')\n",
    "\n",
    "    model.to(\"cpu\")\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return model, train_losses, val_losses"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1534/1534 [05:56<00:00,  4.31it/s]\n",
      "100%|██████████| 334/334 [01:14<00:00,  4.48it/s]\n",
      "  0%|          | 0/1534 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 10620 tn: 26714 fp: 1860 fn: 3506\n",
      "Balanced Accuracy:  0.8433555202033799  Specificity:  0.9349058584727374  Sensitivity:  0.7518051819340223  Precision:  0.8509615384615384\n",
      "Epoch: 0/10... Loss: 0.3739... Val Loss: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1534/1534 [05:46<00:00,  4.43it/s]\n",
      "100%|██████████| 334/334 [01:17<00:00,  4.31it/s]\n",
      "  0%|          | 0/1534 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 10447 tn: 26987 fp: 1587 fn: 3679\n",
      "Balanced Accuracy:  0.8420091299810768  Specificity:  0.944459998600126  Sensitivity:  0.7395582613620275  Precision:  0.8681236496592987\n",
      "Epoch: 1/10... Loss: 0.3447... Val Loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1534/1534 [06:02<00:00,  4.23it/s]\n",
      "100%|██████████| 334/334 [01:17<00:00,  4.31it/s]\n",
      "  0%|          | 0/1534 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 10587 tn: 26871 fp: 1703 fn: 3539\n",
      "Balanced Accuracy:  0.8449347140521476  Specificity:  0.9404003639672429  Sensitivity:  0.7494690641370523  Precision:  0.8614320585842148\n",
      "Epoch: 2/10... Loss: 0.3353... Val Loss: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1534/1534 [05:55<00:00,  4.32it/s]\n",
      "100%|██████████| 334/334 [01:17<00:00,  4.31it/s]\n",
      "  0%|          | 0/1534 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 9979 tn: 27240 fp: 1334 fn: 4147\n",
      "Balanced Accuracy:  0.8298710326179662  Specificity:  0.953314201721845  Sensitivity:  0.7064278635140875  Precision:  0.8820825598868558\n",
      "Epoch: 3/10... Loss: 0.3291... Val Loss: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1534/1534 [05:58<00:00,  4.28it/s]\n",
      "100%|██████████| 334/334 [01:15<00:00,  4.42it/s]\n",
      "  0%|          | 0/301 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 10139 tn: 27122 fp: 1452 fn: 3987\n",
      "Balanced Accuracy:  0.833469534322684  Specificity:  0.949184573388395  Sensitivity:  0.717754495256973  Precision:  0.8747303942714175\n",
      "Epoch: 4/10... Loss: 0.3241... Val Loss: 0.0104\n",
      "Early Stop no improvement in validation loss in 2 validation steps\n",
      "\n",
      "Lowest Validation Loss: 0.010067480175118697 at epoch 2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/301 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-15-7733d4c29b70>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     15\u001B[0m         \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mset_to_none\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 17\u001B[1;33m         \u001B[0mtest_output\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_inputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     18\u001B[0m         \u001B[0mtest_preds\u001B[0m\u001B[1;33m+=\u001B[0m\u001B[0mtest_output\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m         \u001B[0mtest_targets_list\u001B[0m\u001B[1;33m+=\u001B[0m\u001B[0mtest_targets\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\spencer\\documents\\pytorch\\venv\\lib\\site-packages\\torchvision\\models\\efficientnet.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    210\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    211\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 212\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_forward_impl\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    213\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\spencer\\documents\\pytorch\\venv\\lib\\site-packages\\torchvision\\models\\efficientnet.py\u001B[0m in \u001B[0;36m_forward_impl\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    200\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    201\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_forward_impl\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 202\u001B[1;33m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    203\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    204\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mavgpool\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\spencer\\documents\\pytorch\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\spencer\\documents\\pytorch\\venv\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    139\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    140\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 141\u001B[1;33m             \u001B[0minput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    142\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    143\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\spencer\\documents\\pytorch\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\spencer\\documents\\pytorch\\venv\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    139\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    140\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 141\u001B[1;33m             \u001B[0minput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    142\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    143\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\spencer\\documents\\pytorch\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\spencer\\documents\\pytorch\\venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    444\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    445\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 446\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    447\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    448\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mConv3d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_ConvNd\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\spencer\\documents\\pytorch\\venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    440\u001B[0m                             \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstride\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    441\u001B[0m                             _pair(0), self.dilation, self.groups)\n\u001B[1;32m--> 442\u001B[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001B[0m\u001B[0;32m    443\u001B[0m                         self.padding, self.dilation, self.groups)\n\u001B[0;32m    444\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "model, train_losses, val_losses = train(model, train_dataloader, val_dataloader, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [01:09<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  0.010843710553261542\n",
      "tp: 8854 tn: 24952 fp: 2483 fn: 2239\n",
      "Balanced Accuracy:  0.8538280864183687  Specificity:  0.9094951704027702  Sensitivity:  0.7981610024339674  Precision:  0.7809826232689424\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.eval()\n",
    "test_preds, test_targets_list = [], []\n",
    "test_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for test_inputs, test_targets in tqdm(test_dataloader):\n",
    "\n",
    "        test_inputs, test_targets = test_inputs.to(device), test_targets.to(device)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "\n",
    "        test_output = model.forward(test_inputs).squeeze()\n",
    "        test_preds+=test_output\n",
    "        test_targets_list+=test_targets\n",
    "\n",
    "        test_loss += criterion(test_output, test_targets.float())\n",
    "\n",
    "    print(\"Test Loss: \", test_loss.item()/((len(test_dataloader.dataset)%BATCH_SIZE)*BATCH_SIZE))\n",
    "\n",
    "    compute_performance(torch.sigmoid(torch.Tensor(test_preds)), torch.Tensor(test_targets_list), 0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Neg:  0.7270911259007103\n",
      "Percent Pos:  0.2729088740992896\n",
      "Neg Count:  142680 Pos Count:  53554\n",
      "\n",
      "Class Percentages After Splitting\n",
      "Percent Neg Train1:  0.47036018751112607 Percent Pos Train 1:  0.5296398124888739\n",
      "Percent Neg Train2:  0.47036018751112607 Percent Pos Train 2:  0.5296398124888739\n",
      "Percent Neg Train3:  0.47036018751112607 Percent Pos Train 3:  0.5296398124888739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\spencer\\documents\\pytorch\\venv\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n",
      "c:\\users\\spencer\\documents\\pytorch\\venv\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n",
      "c:\\users\\spencer\\documents\\pytorch\\venv\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n",
      "c:\\users\\spencer\\documents\\pytorch\\venv\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1800x360 with 4 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Percent Neg: \", (df_train['class'].to_list()).count(0)/len(df_train))\n",
    "print(\"Percent Pos: \", (df_train['class'].to_list()).count(1)/len(df_train))\n",
    "\n",
    "df_train_neg = df_train.loc[df_train['class']==0]\n",
    "df_train_pos = df_train.loc[df_train['class']==1]\n",
    "print(\"Neg Count: \", len(df_train_neg), \"Pos Count: \",len(df_train_pos))\n",
    "\n",
    "#split it into 3 since i would rater the model have an over represented positive class so the model\n",
    "#predicts pos more than neg since identifying pos is more important\n",
    "df_train1, temp = train_test_split(df_train_neg, train_size=1/3, random_state=42)\n",
    "df_train2, df_train3 = train_test_split(temp, train_size=1/2, random_state=42)\n",
    "df_train1 = pd.concat([df_train1, df_train_pos], ignore_index=True)\n",
    "df_train2 = pd.concat([df_train2, df_train_pos], ignore_index=True)\n",
    "df_train3 = pd.concat([df_train3, df_train_pos], ignore_index=True)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,4,figsize=(25,5))\n",
    "sns.countplot(df_train['class'], ax=ax[0], palette=\"Reds\")\n",
    "ax[0].set_title(\"Original Train Data\")\n",
    "sns.countplot(df_train1['class'], ax=ax[1], palette=\"Blues\")\n",
    "ax[1].set_title(\"Balanced Train Data 1\")\n",
    "sns.countplot(df_train2['class'], ax=ax[2], palette=\"Greens\")\n",
    "ax[2].set_title(\"Balanced Train Data 2\")\n",
    "sns.countplot(df_train3['class'], ax=ax[3], palette=\"Oranges\")\n",
    "ax[3].set_title(\"Balanced Train Data 3\")\n",
    "\n",
    "print(\"\\nClass Percentages After Splitting\")\n",
    "print(\"Percent Neg Train1: \", (df_train1['class'].to_list()).count(0)/len(df_train1), \"Percent Pos Train 1: \", (df_train1['class'].to_list()).count(1)/len(df_train1))\n",
    "print(\"Percent Neg Train2: \", (df_train2['class'].to_list()).count(0)/len(df_train2), \"Percent Pos Train 2: \", (df_train2['class'].to_list()).count(1)/len(df_train2))\n",
    "print(\"Percent Neg Train3: \", (df_train3['class'].to_list()).count(0)/len(df_train3), \"Percent Pos Train 3: \", (df_train3['class'].to_list()).count(1)/len(df_train3))\n",
    "\n",
    "train_dataloaders = [DataLoader(CustomImageDataset(df_train1, transform=transform), batch_size=BATCH_SIZE, shuffle=True), DataLoader(CustomImageDataset(df_train2, transform=transform), batch_size=BATCH_SIZE, shuffle=True), DataLoader(CustomImageDataset(df_train3, transform=transform), batch_size=BATCH_SIZE, shuffle=True)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def init_models(dataloaders, load_save=False):\n",
    "    if load_save:\n",
    "        ensemble = [models.efficientnet_b0(pretrained=True) for _ in dataloaders]\n",
    "\n",
    "        for model in ensemble:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            model.classifier = nn.Sequential(\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(1280, 512),\n",
    "                nn.BatchNorm1d(512),\n",
    "                nn.ReLU(),\n",
    "\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(512, 256),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU(),\n",
    "\n",
    "                nn.Linear(256, 1))\n",
    "\n",
    "            model.apply(init_weights)\n",
    "    else:\n",
    "        ensemble = [[models.efficientnet_b0(pretrained=True), data] for data in dataloaders]\n",
    "\n",
    "        for model, _ in ensemble:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            model.classifier = nn.Sequential(\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(1280, 512),\n",
    "                nn.BatchNorm1d(512),\n",
    "                nn.ReLU(),\n",
    "\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(512, 256),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU(),\n",
    "\n",
    "                nn.Linear(256, 1))\n",
    "\n",
    "            model.apply(init_weights)\n",
    "    return ensemble"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 790/790 [02:56<00:00,  4.48it/s]\n",
      "100%|██████████| 334/334 [01:11<00:00,  4.69it/s]\n",
      "  0%|          | 0/790 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 12120 tn: 25057 fp: 3517 fn: 2006\n",
      "Balanced Accuracy:  0.867454216038297  Specificity:  0.8769160775530203  Sensitivity:  0.8579923545235736  Precision:  0.7750847349235787\n",
      "Epoch: 0/10... Loss: 0.0185... Val Loss: 0.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 790/790 [02:54<00:00,  4.52it/s]\n",
      "100%|██████████| 334/334 [01:12<00:00,  4.59it/s]\n",
      "  0%|          | 0/790 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 11851 tn: 25366 fp: 3208 fn: 2275\n",
      "Balanced Accuracy:  0.8633397795982306  Specificity:  0.8877301042906138  Sensitivity:  0.8389494549058474  Precision:  0.7869712464307059\n",
      "Epoch: 1/10... Loss: 0.0170... Val Loss: 0.0105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 790/790 [02:56<00:00,  4.48it/s]\n",
      "100%|██████████| 334/334 [01:13<00:00,  4.54it/s]\n",
      "  0%|          | 0/790 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 11952 tn: 25470 fp: 3104 fn: 2174\n",
      "Balanced Accuracy:  0.8687345839568195  Specificity:  0.8913697767200952  Sensitivity:  0.8460993911935438  Precision:  0.793836344314559\n",
      "Epoch: 2/10... Loss: 0.0165... Val Loss: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 790/790 [02:56<00:00,  4.47it/s]\n",
      "100%|██████████| 334/334 [01:13<00:00,  4.54it/s]\n",
      "  0%|          | 0/790 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 12048 tn: 25439 fp: 3135 fn: 2078\n",
      "Balanced Accuracy:  0.8715901223002913  Specificity:  0.8902848743613074  Sensitivity:  0.8528953702392751  Precision:  0.7935190673779885\n",
      "Epoch: 3/10... Loss: 0.0162... Val Loss: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 790/790 [02:55<00:00,  4.49it/s]\n",
      "100%|██████████| 334/334 [01:10<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 11780 tn: 25698 fp: 2876 fn: 2346\n",
      "Balanced Accuracy:  0.8666361603273347  Specificity:  0.8993490585847274  Sensitivity:  0.8339232620699419  Precision:  0.8037663755458515\n",
      "Epoch: 4/10... Loss: 0.0160... Val Loss: 0.0101\n",
      "Early Stop no improvement in validation loss in 1 validation steps\n",
      "\n",
      "Lowest Validation Loss: 0.010013646985355177 at epoch 3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 790/790 [02:52<00:00,  4.57it/s]\n",
      "100%|██████████| 334/334 [01:11<00:00,  4.66it/s]\n",
      "  0%|          | 0/790 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 11872 tn: 25659 fp: 2915 fn: 2254\n",
      "Balanced Accuracy:  0.8692101283728865  Specificity:  0.8979841814236719  Sensitivity:  0.8404360753221011  Precision:  0.8028673835125448\n",
      "Epoch: 0/10... Loss: 0.0187... Val Loss: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 790/790 [02:59<00:00,  4.41it/s]\n",
      "100%|██████████| 334/334 [01:13<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 12273 tn: 25014 fp: 3560 fn: 1853\n",
      "Balanced Accuracy:  0.8721173295592692  Specificity:  0.8754112129908308  Sensitivity:  0.8688234461277078  Precision:  0.7751531611191814\n",
      "Epoch: 1/10... Loss: 0.0170... Val Loss: 0.0103\n",
      "Early Stop no improvement in validation loss in 1 validation steps\n",
      "\n",
      "Lowest Validation Loss: 0.010000115946719521 at epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 790/790 [03:07<00:00,  4.21it/s]\n",
      "100%|██████████| 334/334 [01:13<00:00,  4.52it/s]\n",
      "  0%|          | 0/790 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 12386 tn: 24533 fp: 4041 fn: 1740\n",
      "Balanced Accuracy:  0.8677003039003002  Specificity:  0.8585777280044796  Sensitivity:  0.8768228797961206  Precision:  0.7540025567662993\n",
      "Epoch: 0/10... Loss: 0.0186... Val Loss: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 790/790 [02:55<00:00,  4.49it/s]\n",
      "100%|██████████| 334/334 [01:15<00:00,  4.42it/s]\n",
      "  0%|          | 0/790 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 12218 tn: 24958 fp: 3616 fn: 1908\n",
      "Balanced Accuracy:  0.8691906529205236  Specificity:  0.8734513893749563  Sensitivity:  0.8649299164660909  Precision:  0.7716306681823923\n",
      "Epoch: 1/10... Loss: 0.0170... Val Loss: 0.0106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 790/790 [02:58<00:00,  4.42it/s]\n",
      "100%|██████████| 334/334 [01:15<00:00,  4.44it/s]\n",
      "  0%|          | 0/790 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 12059 tn: 25295 fp: 3279 fn: 2067\n",
      "Balanced Accuracy:  0.8694597020460428  Specificity:  0.8852453279204872  Sensitivity:  0.8536740761715985  Precision:  0.7862172382318425\n",
      "Epoch: 2/10... Loss: 0.0166... Val Loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 790/790 [02:57<00:00,  4.46it/s]\n",
      "100%|██████████| 334/334 [01:14<00:00,  4.51it/s]\n",
      "  0%|          | 0/790 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 11912 tn: 25828 fp: 2746 fn: 2214\n",
      "Balanced Accuracy:  0.8735831911897007  Specificity:  0.903898649121579  Sensitivity:  0.8432677332578224  Precision:  0.812662027561741\n",
      "Epoch: 3/10... Loss: 0.0161... Val Loss: 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 790/790 [02:58<00:00,  4.42it/s]\n",
      "100%|██████████| 334/334 [01:15<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 11968 tn: 25302 fp: 3272 fn: 2158\n",
      "Balanced Accuracy:  0.8663611801201518  Specificity:  0.8854903058724715  Sensitivity:  0.8472320543678323  Precision:  0.7853018372703412\n",
      "Epoch: 4/10... Loss: 0.0159... Val Loss: 0.0104\n",
      "Early Stop no improvement in validation loss in 1 validation steps\n",
      "\n",
      "Lowest Validation Loss: 0.009700070870550056 at epoch 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble = init_models(dataloaders=train_dataloaders)\n",
    "trained_ensemble = []\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "for mod, dataloader_train in ensemble:\n",
    "    model, train_losses, val_losses = train(mod, dataloader_train, val_dataloader, early_stop=1, device=device)\n",
    "    trained_ensemble.append(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [01:56<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  0.01232055983235759\n",
      "tp: 9830 tn: 23287 fp: 4150 fn: 1261\n",
      "Balanced Accuracy:  0.8675243034372295  Specificity:  0.8487443962532347  AUROC Score:  0.9400881192509194  Sensitivity:  0.8863042106212244  Precision:  0.7031473533619457\n"
     ]
    }
   ],
   "source": [
    "def ensemble_predict(models, dataloader_test, device='cpu'):\n",
    "    for mod in models:\n",
    "        mod.to(device)\n",
    "        mod.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    test_preds, test_targets_list = [], []\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_inputs, test_targets in tqdm(dataloader_test):\n",
    "\n",
    "            test_inputs, test_targets = test_inputs.to(device), test_targets.to(device)\n",
    "            batch_output=[]\n",
    "\n",
    "            for model in models:\n",
    "                model.zero_grad(set_to_none=True)\n",
    "                batch_output.append(torch.sigmoid(model.forward(test_inputs).squeeze()).cpu().numpy())\n",
    "\n",
    "            #average models output\n",
    "            batch_output = np.column_stack(batch_output)\n",
    "            test_output = np.mean(batch_output, axis=1)\n",
    "\n",
    "            test_preds = np.hstack((test_preds, test_output))\n",
    "            test_targets_list+=test_targets\n",
    "            test_loss += criterion(torch.tensor(test_output).to(device), test_targets.float())\n",
    "\n",
    "        print(\"Test Loss: \", test_loss.item()/((len(dataloader_test.dataset)%BATCH_SIZE)*BATCH_SIZE))\n",
    "\n",
    "        compute_performance(torch.Tensor(test_preds), torch.Tensor(test_targets_list), 0.5)\n",
    "\n",
    "load_save = True\n",
    "\n",
    "if load_save:\n",
    "    checkpoint1 = torch.load('BestModels/Ensemble_1/2021-11-21_17-33_E_3_TL_0.0162_VL_0.01.pt')\n",
    "    checkpoint2 = torch.load('BestModels/Ensemble_1/2021-11-21_17-41_E_0_TL_0.0187_VL_0.01.pt')\n",
    "    checkpoint3 = torch.load('BestModels/Ensemble_1/2021-11-21_18-03_E_3_TL_0.0161_VL_0.0097.pt')\n",
    "\n",
    "    trained_ensemble = init_models(dataloaders=train_dataloaders, load_save=load_save)\n",
    "\n",
    "    trained_ensemble[0].load_state_dict(checkpoint1['model_state_dict'])\n",
    "    trained_ensemble[1].load_state_dict(checkpoint2['model_state_dict'])\n",
    "    trained_ensemble[2].load_state_dict(checkpoint3['model_state_dict'])\n",
    "\n",
    "ensemble_predict(trained_ensemble, test_dataloader, device='cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}