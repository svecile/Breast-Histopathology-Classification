{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.io import read_image\n",
    "from torchsummary import summary\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import wandb\n",
    "from ece9603_project import lossFunctions\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device=\"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run once to setup connection to wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n# Setup sweep hyperparameters\\nsweep_config = {\\n    \\'name\\': \\'ensemble_sweep\\',\\n    \\'method\\': \\'grid\\',\\n    \\'parameters\\': {\\n        \\'learning_rate\\': {\\n            \\'values\\': [0.001]\\n        },\\n        \\'epochs\\': {\\n            \\'values\\': [10]\\n        },\\n        \\'loss_function\\': {\\n            \\'values\\': [\\'dice_loss\\',\\n                       \\'bce_dice_loss\\',\\n                       \\'jaccard_iou_loss\\',\\n                       \\'focal_loss\\',\\n                       \\'tversky_loss\\',\\n                       \\'focal_tversky_loss\\',\\n                       \\'bce_with_logits_loss\\']\\n        }\\n    }\\n}\\nsweep_id = wandb.sweep(sweep_config,\\n                       project=\"breast-histopathology-classification\",\\n                       entity=\"ece9603_project\")\\n'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Setup sweep hyperparameters\n",
    "sweep_config = {\n",
    "    'name': 'ensemble_sweep',\n",
    "    'method': 'grid',\n",
    "    'parameters': {\n",
    "        'learning_rate': {\n",
    "            'values': [0.001]\n",
    "        },\n",
    "        'epochs': {\n",
    "            'values': [10]\n",
    "        },\n",
    "        'loss_function': {\n",
    "            'values': ['dice_loss',\n",
    "                       'bce_dice_loss',\n",
    "                       'jaccard_iou_loss',\n",
    "                       'focal_loss',\n",
    "                       'tversky_loss',\n",
    "                       'focal_tversky_loss',\n",
    "                       'bce_with_logits_loss']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "sweep_id = wandb.sweep(sweep_config,\n",
    "                       project=\"breast-histopathology-classification\",\n",
    "                       entity=\"ece9603_project\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.info = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.info)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.info.imgPath.values[idx]\n",
    "        label = self.info['class'].values[idx]\n",
    "        image = read_image(path, mode=torchvision.io.image.ImageReadMode.RGB).float()\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   patient  class  posX  posY                                         imgPath\n",
      "0    12954      0  1151  1401  data/12954/0/12954_idx5_x1151_y1401_class0.png\n",
      "1    12954      0  1951  2901  data/12954/0/12954_idx5_x1951_y2901_class0.png\n",
      "2    12954      0   151   501    data/12954/0/12954_idx5_x151_y501_class0.png\n",
      "3    12954      0  1701  2251  data/12954/0/12954_idx5_x1701_y2251_class0.png\n",
      "4    12954      0  1501  2001  data/12954/0/12954_idx5_x1501_y2001_class0.png\n",
      "Number of Unique Patients:  279\n",
      "   patient  class  posX  posY                                         imgPath\n",
      "0    12954      0  1151  1401  data/12954/0/12954_idx5_x1151_y1401_class0.png\n",
      "1    12954      0  1951  2901  data/12954/0/12954_idx5_x1951_y2901_class0.png\n",
      "2    12954      0   151   501    data/12954/0/12954_idx5_x151_y501_class0.png\n",
      "3    12954      0  1701  2251  data/12954/0/12954_idx5_x1701_y2251_class0.png\n",
      "4    12954      0  1501  2001  data/12954/0/12954_idx5_x1501_y2001_class0.png\n",
      "Number of Train Patients:  195\n",
      "      patient  class  posX  posY  \\\n",
      "6566    15634      0  2401  1801   \n",
      "6567    15634      0  1001  1651   \n",
      "6568    15634      0  2051  1351   \n",
      "6569    15634      0  1301  2201   \n",
      "6570    15634      0  1351  1301   \n",
      "\n",
      "                                             imgPath  \n",
      "6566  data/15634/0/15634_idx5_x2401_y1801_class0.png  \n",
      "6567  data/15634/0/15634_idx5_x1001_y1651_class0.png  \n",
      "6568  data/15634/0/15634_idx5_x2051_y1351_class0.png  \n",
      "6569  data/15634/0/15634_idx5_x1301_y2201_class0.png  \n",
      "6570  data/15634/0/15634_idx5_x1351_y1301_class0.png  \n",
      "Number of Validation Patients:  42\n",
      "      patient  class  posX  posY  \\\n",
      "7926    13687      0  2251   251   \n",
      "7927    13687      0  2801   751   \n",
      "7928    13687      0  1551   701   \n",
      "7929    13687      0  1251   651   \n",
      "7930    13687      0  2851  1251   \n",
      "\n",
      "                                             imgPath  \n",
      "7926   data/13687/0/13687_idx5_x2251_y251_class0.png  \n",
      "7927   data/13687/0/13687_idx5_x2801_y751_class0.png  \n",
      "7928   data/13687/0/13687_idx5_x1551_y701_class0.png  \n",
      "7929   data/13687/0/13687_idx5_x1251_y651_class0.png  \n",
      "7930  data/13687/0/13687_idx5_x2851_y1251_class0.png  \n",
      "Number of Test Patients:  42\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv(\"breastCancerDataframe.csv\", index_col=0)\n",
    "print(df.head())\n",
    "\n",
    "patientIDs = df.patient.unique()\n",
    "print(\"Number of Unique Patients: \", len(patientIDs))\n",
    "\n",
    "patients_train, temp = train_test_split(patientIDs, test_size=0.3, random_state=42)\n",
    "patients_val, patients_test = train_test_split(temp, test_size=0.5, random_state=42)\n",
    "\n",
    "df_train = df.loc[df['patient'].isin(patients_train)]\n",
    "print(df_train.head())\n",
    "print(\"Number of Train Patients: \", df_train.patient.nunique())\n",
    "\n",
    "df_val = df.loc[df['patient'].isin(patients_val)]\n",
    "print(df_val.head())\n",
    "print(\"Number of Validation Patients: \", df_val.patient.nunique())\n",
    "\n",
    "df_test = df.loc[df['patient'].isin(patients_test)]\n",
    "print(df_test.head())\n",
    "print(\"Number of Test Patients: \", df_test.patient.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "train_dataset = CustomImageDataset(df_train, transform=transform)\n",
    "val_dataset = CustomImageDataset(df_val, transform=transform)\n",
    "test_dataset = CustomImageDataset(df_test, transform=transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nprint(\"Percent Neg: \", (df_train[\\'class\\'].to_list()).count(0)/len(df_train))\\nprint(\"Percent Pos: \", (df_train[\\'class\\'].to_list()).count(1)/len(df_train))\\n\\ndf_train_neg = df_train.loc[df_train[\\'class\\']==0]\\ndf_train_pos = df_train.loc[df_train[\\'class\\']==1]\\nprint(\"Neg Count: \", len(df_train_neg), \"Pos Count: \",len(df_train_pos))\\n\\n#split it into 3 since i would rather the model have an over represented positive class so the model\\n#predicts pos more than neg since identifying pos is more important\\ndf_train1, temp = train_test_split(df_train_neg, train_size=1/3, random_state=42)\\ndf_train2, df_train3 = train_test_split(temp, train_size=1/2, random_state=42)\\ndf_train1 = pd.concat([df_train1, df_train_pos], ignore_index=True)\\ndf_train2 = pd.concat([df_train2, df_train_pos], ignore_index=True)\\ndf_train3 = pd.concat([df_train3, df_train_pos], ignore_index=True)\\n\\n\\nfig, ax = plt.subplots(1,4,figsize=(25,5))\\nsns.countplot(df_train[\\'class\\'], ax=ax[0], palette=\"Reds\")\\nax[0].set_title(\"Original Train Data\")\\nsns.countplot(df_train1[\\'class\\'], ax=ax[1], palette=\"Blues\")\\nax[1].set_title(\"Balanced Train Data 1\")\\nsns.countplot(df_train2[\\'class\\'], ax=ax[2], palette=\"Greens\")\\nax[2].set_title(\"Balanced Train Data 2\")\\nsns.countplot(df_train3[\\'class\\'], ax=ax[3], palette=\"Oranges\")\\nax[3].set_title(\"Balanced Train Data 3\")\\n\\nprint(\"\\nClass Percentages After Splitting\")\\nprint(\"Percent Neg Train1: \", (df_train1[\\'class\\'].to_list()).count(0)/len(df_train1), \"Percent Pos Train 1: \", (df_train1[\\'class\\'].to_list()).count(1)/len(df_train1))\\nprint(\"Percent Neg Train2: \", (df_train2[\\'class\\'].to_list()).count(0)/len(df_train2), \"Percent Pos Train 2: \", (df_train2[\\'class\\'].to_list()).count(1)/len(df_train2))\\nprint(\"Percent Neg Train3: \", (df_train3[\\'class\\'].to_list()).count(0)/len(df_train3), \"Percent Pos Train 3: \", (df_train3[\\'class\\'].to_list()).count(1)/len(df_train3))\\n\\ntrain_dataloaders = [DataLoader(CustomImageDataset(df_train1, transform=transform), batch_size=BATCH_SIZE, shuffle=True),\\n                     DataLoader(CustomImageDataset(df_train2, transform=transform), batch_size=BATCH_SIZE, shuffle=True),\\n                     DataLoader(CustomImageDataset(df_train3, transform=transform), batch_size=BATCH_SIZE, shuffle=True)]\\n'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(\"Percent Neg: \", (df_train['class'].to_list()).count(0)/len(df_train))\n",
    "print(\"Percent Pos: \", (df_train['class'].to_list()).count(1)/len(df_train))\n",
    "\n",
    "df_train_neg = df_train.loc[df_train['class']==0]\n",
    "df_train_pos = df_train.loc[df_train['class']==1]\n",
    "print(\"Neg Count: \", len(df_train_neg), \"Pos Count: \",len(df_train_pos))\n",
    "\n",
    "#split it into 3 since i would rather the model have an over represented positive class so the model\n",
    "#predicts pos more than neg since identifying pos is more important\n",
    "df_train1, temp = train_test_split(df_train_neg, train_size=1/3, random_state=42)\n",
    "df_train2, df_train3 = train_test_split(temp, train_size=1/2, random_state=42)\n",
    "df_train1 = pd.concat([df_train1, df_train_pos], ignore_index=True)\n",
    "df_train2 = pd.concat([df_train2, df_train_pos], ignore_index=True)\n",
    "df_train3 = pd.concat([df_train3, df_train_pos], ignore_index=True)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,4,figsize=(25,5))\n",
    "sns.countplot(df_train['class'], ax=ax[0], palette=\"Reds\")\n",
    "ax[0].set_title(\"Original Train Data\")\n",
    "sns.countplot(df_train1['class'], ax=ax[1], palette=\"Blues\")\n",
    "ax[1].set_title(\"Balanced Train Data 1\")\n",
    "sns.countplot(df_train2['class'], ax=ax[2], palette=\"Greens\")\n",
    "ax[2].set_title(\"Balanced Train Data 2\")\n",
    "sns.countplot(df_train3['class'], ax=ax[3], palette=\"Oranges\")\n",
    "ax[3].set_title(\"Balanced Train Data 3\")\n",
    "\n",
    "print(\"\\nClass Percentages After Splitting\")\n",
    "print(\"Percent Neg Train1: \", (df_train1['class'].to_list()).count(0)/len(df_train1), \"Percent Pos Train 1: \", (df_train1['class'].to_list()).count(1)/len(df_train1))\n",
    "print(\"Percent Neg Train2: \", (df_train2['class'].to_list()).count(0)/len(df_train2), \"Percent Pos Train 2: \", (df_train2['class'].to_list()).count(1)/len(df_train2))\n",
    "print(\"Percent Neg Train3: \", (df_train3['class'].to_list()).count(0)/len(df_train3), \"Percent Pos Train 3: \", (df_train3['class'].to_list()).count(1)/len(df_train3))\n",
    "\n",
    "train_dataloaders = [DataLoader(CustomImageDataset(df_train1, transform=transform), batch_size=BATCH_SIZE, shuffle=True),\n",
    "                     DataLoader(CustomImageDataset(df_train2, transform=transform), batch_size=BATCH_SIZE, shuffle=True),\n",
    "                     DataLoader(CustomImageDataset(df_train3, transform=transform), batch_size=BATCH_SIZE, shuffle=True)]\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "#split training data for ensomble models\n",
    "def ensemble_train_split(df_train):\n",
    "    #seperate positive and negative samples\n",
    "    df_train_neg = df_train.loc[df_train['class']==0]\n",
    "    df_train_pos = df_train.loc[df_train['class']==1]\n",
    "\n",
    "    #make positive class 10% the size of neg to make skew in pos class more noticeable\n",
    "    df_train_pos_10Percent = df_train_pos.sample(n=int(len(df_train_neg)*0.1), replace=False, random_state=42)\n",
    "    num_folds=int(len(df_train_neg)/len(df_train_pos_10Percent))\n",
    "    print(num_folds)\n",
    "\n",
    "    samples_per_split = int(len(df_train_neg)/num_folds)\n",
    "    #save train dfs incase we want to graph later\n",
    "    train_dataloaders, train_dfs = [], []\n",
    "\n",
    "    for i in range(num_folds):\n",
    "        neg_fold = df_train_neg[i*samples_per_split:(i+1)*samples_per_split]\n",
    "        train_dfs.append(pd.concat([neg_fold, df_train_pos_10Percent], ignore_index=True))\n",
    "        train_dataloaders.append(DataLoader(CustomImageDataset(train_dfs[i], transform=transform), batch_size=BATCH_SIZE, shuffle=True))\n",
    "        print(\"Percent Neg Train fold_\"+str(i)+\": \", ((train_dfs[i])['class'].to_list()).count(0)/len(train_dfs[i]), \"Percent Pos Train fold_\"+str(i)+\": \", ((train_dfs[i])['class'].to_list()).count(1)/len(train_dfs[i]))\n",
    "\n",
    "    return train_dataloaders\n",
    "\n",
    "# Calculate performance measures\n",
    "def compute_performance(yhat, y, pos_cutoff, evaluation_phase='validation',\n",
    "                        model_id=0):\n",
    "\n",
    "    # First, get tp, tn, fp, fn\n",
    "    tp = sum(np.logical_and(yhat >= pos_cutoff, y == 1).numpy())\n",
    "    tn = sum(np.logical_and(yhat < pos_cutoff, y == 0).numpy())\n",
    "    fp = sum(np.logical_and(yhat >= pos_cutoff, y == 0).numpy())\n",
    "    fn = sum(np.logical_and(yhat < pos_cutoff, y == 1).numpy())\n",
    "\n",
    "    print(f\"tp: {tp} tn: {tn} fp: {fp} fn: {fn}\")\n",
    "\n",
    "    # Precision\n",
    "    # \"Of the ones I labeled +, how many are actually +?\"\n",
    "    precision = tp / (tp + fp)\n",
    "\n",
    "    # Recall\n",
    "    # \"Of all the + in the data, how many do I correctly label?\"\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    # Sensitivity\n",
    "    # \"Of all the + in the data, how many do I correctly label?\"\n",
    "    sensitivity = recall\n",
    "\n",
    "    # Specificity\n",
    "    # \"Of all the - in the data, how many do I correctly label?\"\n",
    "    specificity = tn / (fp + tn)\n",
    "\n",
    "    balanced_acc = 0.5*(sensitivity+specificity)\n",
    "    #fMeasure =  2*((precision*recall)/(precision+recall))\n",
    "\n",
    "    auroc = roc_auc_score(y, yhat)\n",
    "\n",
    "    # Print results\n",
    "    print(\"Balanced Accuracy: \", balanced_acc,\" Specificity: \",specificity, \" AUROC Score: \", auroc,\n",
    "          \" Sensitivity: \", sensitivity,\" Precision: \", precision)\n",
    "    # Log results to WandB\n",
    "    wandb.log({\"(model-{}-{}) Balanced Accuracy\".format(model_id, evaluation_phase): balanced_acc,\n",
    "               \"(model-{}-{}) Specificity\".format(model_id, evaluation_phase): specificity,\n",
    "               \"(model-{}-{}) Sensitivity\".format(model_id, evaluation_phase): sensitivity,\n",
    "               \"(model-{}-{}) Precision\".format(model_id, evaluation_phase): precision,\n",
    "               \"(model-{}-{}) AUROC Score\".format(model_id, evaluation_phase): auroc},\n",
    "              commit=False)\n",
    "\n",
    "def train(model, dataloader_train, dataloader_val, device='cpu', epochs=10, early_stop=2, lr=0.001,\n",
    "          loss_function='bce_with_logits_loss', model_id=0, verbose=True):\n",
    "\n",
    "    opt = torch.optim.Adam(model.classifier.parameters(), lr=lr)\n",
    "\n",
    "    criterion = lossFunctions.getLossFunction(loss_function)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    lowest_val_loss, train_loss = np.inf, 0\n",
    "    lowest_val_epoch = 0\n",
    "    epochs_wo_improvement = 0\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    train_losses, val_losses=[], []\n",
    "    train_preds, train_targets_list = [], []\n",
    "\n",
    "    for e in range(epochs):\n",
    "        epoch_train_loss = 0\n",
    "        epoch_val_loss = 0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for inputs, targets in tqdm(dataloader_train):\n",
    "\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            model.zero_grad(set_to_none=True)\n",
    "\n",
    "            train_output = model.forward(inputs).squeeze()\n",
    "            train_preds+=train_output\n",
    "            train_targets_list+=targets\n",
    "            loss = criterion(train_output, targets.float())\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            epoch_train_loss+=loss\n",
    "\n",
    "        compute_performance(torch.sigmoid(torch.Tensor(train_preds)), torch.Tensor(train_targets_list), 0.5, evaluation_phase='training', model_id=model_id)\n",
    "        epoch_train_loss = epoch_train_loss.item()/((len(dataloader_train.dataset)%BATCH_SIZE)*BATCH_SIZE)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "\n",
    "        #VALIDATION\n",
    "\n",
    "        model.eval()\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        val_preds, val_targets_list = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in tqdm(dataloader_val):\n",
    "\n",
    "                val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "\n",
    "                val_output = model.forward(val_inputs).squeeze()\n",
    "                val_preds+=val_output\n",
    "                val_targets_list+=val_targets\n",
    "\n",
    "                epoch_val_loss += criterion(val_output, val_targets.float())\n",
    "\n",
    "            epoch_val_loss = epoch_val_loss.item()/((len(dataloader_val.dataset)%BATCH_SIZE)*BATCH_SIZE)\n",
    "            val_losses.append(epoch_val_loss)\n",
    "\n",
    "            compute_performance(torch.sigmoid(torch.Tensor(val_preds)), torch.Tensor(val_targets_list), 0.5,\n",
    "                                evaluation_phase='validation', model_id=model_id)\n",
    "\n",
    "        if epoch_val_loss <= lowest_val_loss:\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            lowest_val_loss = epoch_val_loss\n",
    "            train_loss=epoch_train_loss\n",
    "            lowest_val_epoch=e\n",
    "            epochs_wo_improvement=0\n",
    "        else:\n",
    "            epochs_wo_improvement+=1\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Epoch: {}/{}...\".format(e, epochs), \"Loss: {:.4f}...\".format(epoch_train_loss), \"Val Loss: {:.4f}\".format(epoch_val_loss),)\n",
    "\n",
    "        # Log to wandb project\n",
    "        wandb.log({\"(model-{}) training_loss\".format(model_id): epoch_train_loss,\n",
    "                   \"(model-{}) validation_loss\".format(model_id): epoch_val_loss})\n",
    "\n",
    "        #early stopping\n",
    "        if epochs_wo_improvement>=early_stop:\n",
    "            if verbose:\n",
    "                print(\"Early Stop no improvement in validation loss in \"+str(early_stop)+\" validation steps\")\n",
    "            break\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nLowest Validation Loss: \"+str(lowest_val_loss)+\" at epoch \"+str(lowest_val_epoch)+'\\n')\n",
    "\n",
    "    model.load_state_dict(best_model)\n",
    "    # Record model to wandb\n",
    "    wandb.watch(model)\n",
    "\n",
    "    run_ID = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "    torch.save({'model_state_dict': best_model}, './BestModels/'+str(run_ID)+'_E_'+str(lowest_val_epoch)+'_TL_'+str(round(train_loss, 4))+'_VL_'+str(round(lowest_val_loss, 4))+'.pt')\n",
    "\n",
    "    model.to(\"cpu\")\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "def init_models(dataloaders, load_save=False):\n",
    "\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "\n",
    "    if load_save:\n",
    "        ensemble = [models.efficientnet_b0(pretrained=True) for _ in dataloaders]\n",
    "\n",
    "        for model in ensemble:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            model.classifier = nn.Sequential(\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(1280, 512),\n",
    "                nn.BatchNorm1d(512),\n",
    "                nn.ReLU(),\n",
    "\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(512, 256),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU(),\n",
    "\n",
    "                nn.Linear(256, 1))\n",
    "\n",
    "            model.apply(init_weights)\n",
    "    else:\n",
    "        ensemble = [[models.efficientnet_b0(pretrained=True), data] for data in dataloaders]\n",
    "\n",
    "        for model, _ in ensemble:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            model.classifier = nn.Sequential(\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(1280, 512),\n",
    "                nn.BatchNorm1d(512),\n",
    "                nn.ReLU(),\n",
    "\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(512, 256),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU(),\n",
    "\n",
    "                nn.Linear(256, 1))\n",
    "\n",
    "            model.apply(init_weights)\n",
    "    return ensemble\n",
    "\n",
    "def get_trained_ensemble(dataloaders_train, dataloader_val, loss_function='bce_with_logits_loss'):\n",
    "    ensemble = init_models(dataloaders=dataloaders_train)\n",
    "    trained_ensemble = []\n",
    "\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    model_id = 1\n",
    "    for mod, dataloader_train in ensemble:\n",
    "        model, train_losses, val_losses = train(mod, dataloader_train, dataloader_val, early_stop=1,\n",
    "                                                device=device, loss_function=loss_function, model_id=model_id)\n",
    "        trained_ensemble.append(model)\n",
    "        model_id += 1\n",
    "    return trained_ensemble\n",
    "\n",
    "def ensemble_predict(models, dataloader_test, device='cpu', loss_function='bce_with_logits_loss'):\n",
    "    for mod in models:\n",
    "        mod.to(device)\n",
    "        mod.eval()\n",
    "        mod.zero_grad(set_to_none=True)\n",
    "\n",
    "    test_loss = 0\n",
    "    test_preds, test_targets_list = [], []\n",
    "    criterion = lossFunctions.getLossFunction(loss_function)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_inputs, test_targets in tqdm(dataloader_test):\n",
    "\n",
    "            test_inputs, test_targets = test_inputs.to(device), test_targets.to(device)\n",
    "            batch_output=[]\n",
    "\n",
    "            for model in models:\n",
    "                batch_output.append(torch.sigmoid(model.forward(test_inputs).squeeze()).cpu().numpy())\n",
    "\n",
    "            #average models output\n",
    "            batch_output = np.column_stack(batch_output)\n",
    "            test_output = np.mean(batch_output, axis=1)\n",
    "\n",
    "            test_preds = np.hstack((test_preds, test_output))\n",
    "            test_targets_list+=test_targets\n",
    "            test_loss += criterion(torch.tensor(test_output).to(device), test_targets.float())\n",
    "\n",
    "        print(\"Test Loss: \", test_loss.item()/((len(dataloader_test.dataset)%BATCH_SIZE)*BATCH_SIZE))\n",
    "\n",
    "        compute_performance(torch.Tensor(test_preds), torch.Tensor(test_targets_list), 0.5, \n",
    "                            evaluation_phase=\"testing\")\n",
    "\n",
    "\n",
    "def trainAndTestModel():\n",
    "    config_defaults = {\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"epochs\": 10,\n",
    "        \"loss_function\": \"bce_with_logits_loss\"\n",
    "    }\n",
    "    wandb.init(project=\"breast-histopathology-classification\",\n",
    "               entity=\"ece9603_project\",\n",
    "               job_type=\"model_training\",\n",
    "               config=config_defaults)\n",
    "    config = wandb.config\n",
    "    \n",
    "    trained_ensemble = get_trained_ensemble(ensemble_train_split(df_train), val_dataloader, loss_function=config.loss_function)\n",
    "    ensemble_predict(trained_ensemble, test_dataloader, device='cuda', loss_function=config.loss_function)\n",
    "\n",
    "    # Done this training run\n",
    "    wandb.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Don't really need this\n",
    "\n",
    "``` python\n",
    "load_save = False\n",
    "\n",
    "if load_save:\n",
    "    checkpoint1 = torch.load('BestModels/Ensemble_1/2021-11-21_17-33_E_3_TL_0.0162_VL_0.01.pt')\n",
    "    checkpoint2 = torch.load('BestModels/Ensemble_1/2021-11-21_17-41_E_0_TL_0.0187_VL_0.01.pt')\n",
    "    checkpoint3 = torch.load('BestModels/Ensemble_1/2021-11-21_18-03_E_3_TL_0.0161_VL_0.0097.pt')\n",
    "\n",
    "    trained_ensemble = init_models(dataloaders=train_dataloaders, load_save=load_save)\n",
    "\n",
    "    trained_ensemble[0].load_state_dict(checkpoint1['model_state_dict'])\n",
    "    trained_ensemble[1].load_state_dict(checkpoint2['model_state_dict'])\n",
    "    trained_ensemble[2].load_state_dict(checkpoint3['model_state_dict'])\n",
    "else:\n",
    "    trained_ensemble = get_trained_ensemble(val_dataloader)\n",
    "\n",
    "ensemble_predict(trained_ensemble, test_dataloader, device='cuda')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Finishing last run (ID:3cpcfyx1) before initializing another..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 7204... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c073e1f142144a4b9740779ad8f2fec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>(model-1) training_loss</td><td>▁</td></tr><tr><td>(model-1) validation_loss</td><td>▁</td></tr><tr><td>(model-1-training) AUROC Score</td><td>▁█</td></tr><tr><td>(model-1-training) Balanced Accuracy</td><td>▁█</td></tr><tr><td>(model-1-training) Precision</td><td>▁█</td></tr><tr><td>(model-1-training) Sensitivity</td><td>▁█</td></tr><tr><td>(model-1-training) Specificity</td><td>▁█</td></tr><tr><td>(model-1-validation) AUROC Score</td><td>▁</td></tr><tr><td>(model-1-validation) Balanced Accuracy</td><td>▁</td></tr><tr><td>(model-1-validation) Precision</td><td>▁</td></tr><tr><td>(model-1-validation) Sensitivity</td><td>▁</td></tr><tr><td>(model-1-validation) Specificity</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>(model-1) training_loss</td><td>0.00503</td></tr><tr><td>(model-1) validation_loss</td><td>0.01322</td></tr><tr><td>(model-1-training) AUROC Score</td><td>0.93736</td></tr><tr><td>(model-1-training) Balanced Accuracy</td><td>0.86436</td></tr><tr><td>(model-1-training) Precision</td><td>0.86034</td></tr><tr><td>(model-1-training) Sensitivity</td><td>0.86995</td></tr><tr><td>(model-1-training) Specificity</td><td>0.85877</td></tr><tr><td>(model-1-validation) AUROC Score</td><td>0.9118</td></tr><tr><td>(model-1-validation) Balanced Accuracy</td><td>0.83305</td></tr><tr><td>(model-1-validation) Precision</td><td>0.7061</td></tr><tr><td>(model-1-validation) Sensitivity</td><td>0.83867</td></tr><tr><td>(model-1-validation) Specificity</td><td>0.82743</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">dauntless-brook-45</strong>: <a href=\"https://wandb.ai/ece9603_project/breast-histopathology-classification/runs/3cpcfyx1\" target=\"_blank\">https://wandb.ai/ece9603_project/breast-histopathology-classification/runs/3cpcfyx1</a><br/>\nFind logs at: <code>.\\wandb\\run-20211125_205854-3cpcfyx1\\logs</code><br/>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Successfully finished last run (ID:3cpcfyx1). Initializing new run:<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/ece9603_project/breast-histopathology-classification/runs/2xffr30x\" target=\"_blank\">treasured-sky-46</a></strong> to <a href=\"https://wandb.ai/ece9603_project/breast-histopathology-classification\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Percent Neg Train fold_0:  0.5 Percent Pos Train fold_0:  0.5\n",
      "Percent Neg Train fold_1:  0.5 Percent Pos Train fold_1:  0.5\n",
      "Percent Neg Train fold_2:  0.5 Percent Pos Train fold_2:  0.5\n",
      "Percent Neg Train fold_3:  0.5 Percent Pos Train fold_3:  0.5\n",
      "Percent Neg Train fold_4:  0.5 Percent Pos Train fold_4:  0.5\n",
      "Percent Neg Train fold_5:  0.5 Percent Pos Train fold_5:  0.5\n",
      "Percent Neg Train fold_6:  0.5 Percent Pos Train fold_6:  0.5\n",
      "Percent Neg Train fold_7:  0.5 Percent Pos Train fold_7:  0.5\n",
      "Percent Neg Train fold_8:  0.5 Percent Pos Train fold_8:  0.5\n",
      "Percent Neg Train fold_9:  0.5 Percent Pos Train fold_9:  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:50<00:00,  4.42it/s]\n",
      "  0%|          | 0/334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 12098 tn: 12196 fp: 2072 fn: 2170\n",
      "Balanced Accuracy:  0.8513456686291001  Specificity:  0.8547799271096159  AUROC Score:  0.9267025587478404  Sensitivity:  0.8479114101485843  Precision:  0.8537755822159492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [01:12<00:00,  4.58it/s]\n",
      "  0%|          | 0/223 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 12259 tn: 23238 fp: 5336 fn: 1867\n",
      "Balanced Accuracy:  0.8405445863687927  Specificity:  0.8132568068873801  AUROC Score:  0.9153557745709725  Sensitivity:  0.8678323658502053  Precision:  0.6967320261437908\n",
      "Epoch: 0/10... Loss: 0.0050... Val Loss: 0.0136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:49<00:00,  4.52it/s]\n",
      "  0%|          | 0/334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 24665 tn: 24681 fp: 3855 fn: 3871\n",
      "Balanced Accuracy:  0.8646271376506869  Specificity:  0.8649074852817493  AUROC Score:  0.9374611575930549  Sensitivity:  0.8643467900196243  Precision:  0.8648316970546984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [01:12<00:00,  4.61it/s]\n",
      "  0%|          | 0/223 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 11704 tn: 24348 fp: 4226 fn: 2422\n",
      "Balanced Accuracy:  0.840323211347054  Specificity:  0.8521033107020368  AUROC Score:  0.9177088197344697  Sensitivity:  0.8285431119920713  Precision:  0.7347143753923415\n",
      "Epoch: 1/10... Loss: 0.0043... Val Loss: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:49<00:00,  4.48it/s]\n",
      "  0%|          | 0/334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 37259 tn: 37216 fp: 5588 fn: 5545\n",
      "Balanced Accuracy:  0.8699537426408747  Specificity:  0.869451453135221  AUROC Score:  0.9421930051423439  Sensitivity:  0.8704560321465283  Precision:  0.8695824678507247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [01:13<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 12494 tn: 23001 fp: 5573 fn: 1632\n",
      "Balanced Accuracy:  0.8447154547963825  Specificity:  0.8049625533701967  AUROC Score:  0.9223430941760337  Sensitivity:  0.8844683562225684  Precision:  0.6915370565118725\n",
      "Epoch: 2/10... Loss: 0.0041... Val Loss: 0.0138\n",
      "Early Stop no improvement in validation loss in 1 validation steps\n",
      "\n",
      "Lowest Validation Loss: 0.012669811907567476 at epoch 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:49<00:00,  4.52it/s]\n",
      "  0%|          | 0/334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 11961 tn: 12117 fp: 2151 fn: 2307\n",
      "Balanced Accuracy:  0.843776282590412  Specificity:  0.8492430613961311  AUROC Score:  0.9210251434374643  Sensitivity:  0.838309503784693  Precision:  0.8475765306122449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [01:12<00:00,  4.60it/s]\n",
      "  0%|          | 0/223 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 11673 tn: 24711 fp: 3863 fn: 2453\n",
      "Balanced Accuracy:  0.8455778722234126  Specificity:  0.864807167354938  AUROC Score:  0.9259587425040567  Sensitivity:  0.8263485770918872  Precision:  0.7513516992790937\n",
      "Epoch: 0/10... Loss: 0.0052... Val Loss: 0.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:50<00:00,  4.44it/s]\n",
      "  0%|          | 0/334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 24287 tn: 24629 fp: 3907 fn: 4249\n",
      "Balanced Accuracy:  0.8570927950658818  Specificity:  0.863085225679843  AUROC Score:  0.9322075069925788  Sensitivity:  0.8511003644519204  Precision:  0.8614244165425268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [01:13<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 11482 tn: 25043 fp: 3531 fn: 2644\n",
      "Balanced Accuracy:  0.8446267660489346  Specificity:  0.8764261216490515  AUROC Score:  0.924476380872005  Sensitivity:  0.8128274104488178  Precision:  0.7648038366748817\n",
      "Epoch: 1/10... Loss: 0.0044... Val Loss: 0.0118\n",
      "Early Stop no improvement in validation loss in 1 validation steps\n",
      "\n",
      "Lowest Validation Loss: 0.011673768099985625 at epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:49<00:00,  4.48it/s]\n",
      "  0%|          | 0/334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 11955 tn: 12031 fp: 2237 fn: 2313\n",
      "Balanced Accuracy:  0.8405522848331932  Specificity:  0.843215587328287  AUROC Score:  0.9183642503640315  Sensitivity:  0.8378889823380993  Precision:  0.8423759864712514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [01:14<00:00,  4.50it/s]\n",
      "  0%|          | 0/223 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 11956 tn: 24123 fp: 4451 fn: 2170\n",
      "Balanced Accuracy:  0.8453057881876855  Specificity:  0.844229019388255  AUROC Score:  0.9228060468115847  Sensitivity:  0.846382556987116  Precision:  0.7287133540561955\n",
      "Epoch: 0/10... Loss: 0.0053... Val Loss: 0.0125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:50<00:00,  4.44it/s]\n",
      "  0%|          | 0/334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 24250 tn: 24399 fp: 4137 fn: 4286\n",
      "Balanced Accuracy:  0.852414493972526  Specificity:  0.8550252312867956  AUROC Score:  0.9302386318721225  Sensitivity:  0.8498037566582562  Precision:  0.8542642759009406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [01:13<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 12305 tn: 23942 fp: 4632 fn: 1821\n",
      "Balanced Accuracy:  0.8544916809816155  Specificity:  0.8378945894869462  AUROC Score:  0.9293372652457315  Sensitivity:  0.8710887724762849  Precision:  0.7265159119088387\n",
      "Epoch: 1/10... Loss: 0.0045... Val Loss: 0.0127\n",
      "Early Stop no improvement in validation loss in 1 validation steps\n",
      "\n",
      "Lowest Validation Loss: 0.012498028184238234 at epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:50<00:00,  4.45it/s]\n",
      "  0%|          | 0/334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 11727 tn: 11831 fp: 2437 fn: 2541\n",
      "Balanced Accuracy:  0.8255536865713484  Specificity:  0.8291982057751612  AUROC Score:  0.9059370502658509  Sensitivity:  0.8219091673675357  Precision:  0.8279440835922056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [01:11<00:00,  4.64it/s]\n",
      "  0%|          | 0/223 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 11700 tn: 24966 fp: 3608 fn: 2426\n",
      "Balanced Accuracy:  0.8509956551878617  Specificity:  0.8737313641772241  AUROC Score:  0.9312942125099722  Sensitivity:  0.8282599461984992  Precision:  0.764306245100601\n",
      "Epoch: 0/10... Loss: 0.0057... Val Loss: 0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:50<00:00,  4.39it/s]\n",
      "  0%|          | 0/334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 23849 tn: 23981 fp: 4555 fn: 4687\n",
      "Balanced Accuracy:  0.8380641996075133  Specificity:  0.8403770675637791  AUROC Score:  0.9171564792487343  Sensitivity:  0.8357513316512476  Precision:  0.839635262639065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [01:12<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 12005 tn: 24571 fp: 4003 fn: 2121\n",
      "Balanced Accuracy:  0.8548794731368131  Specificity:  0.8599076083152516  AUROC Score:  0.9306087328255422  Sensitivity:  0.8498513379583746  Precision:  0.7499375312343828\n",
      "Epoch: 1/10... Loss: 0.0050... Val Loss: 0.0118\n",
      "Early Stop no improvement in validation loss in 1 validation steps\n",
      "\n",
      "Lowest Validation Loss: 0.011344891629720988 at epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:49<00:00,  4.49it/s]\n",
      "  0%|          | 0/334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 12222 tn: 12167 fp: 2101 fn: 2046\n",
      "Balanced Accuracy:  0.8546747967479675  Specificity:  0.8527474067844126  AUROC Score:  0.9286999447439299  Sensitivity:  0.8566021867115223  Precision:  0.853312853452489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [01:12<00:00,  4.61it/s]\n",
      "  0%|          | 0/223 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 12402 tn: 24182 fp: 4392 fn: 1724\n",
      "Balanced Accuracy:  0.8621246882626945  Specificity:  0.84629383355498  AUROC Score:  0.9350522551087349  Sensitivity:  0.8779555429704091  Precision:  0.7384780278670954\n",
      "Epoch: 0/10... Loss: 0.0050... Val Loss: 0.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:50<00:00,  4.44it/s]\n",
      "  0%|          | 0/334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 24778 tn: 24693 fp: 3843 fn: 3758\n",
      "Balanced Accuracy:  0.8668173535183628  Specificity:  0.8653280067283431  AUROC Score:  0.9389629585878527  Sensitivity:  0.8683067003083824  Precision:  0.8657279619859544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [01:13<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 12433 tn: 23668 fp: 4906 fn: 1693\n",
      "Balanced Accuracy:  0.8542277651899337  Specificity:  0.8283054525092741  AUROC Score:  0.9287192918742367  Sensitivity:  0.8801500778705932  Precision:  0.7170540400253763\n",
      "Epoch: 1/10... Loss: 0.0042... Val Loss: 0.0125\n",
      "Early Stop no improvement in validation loss in 1 validation steps\n",
      "\n",
      "Lowest Validation Loss: 0.011610013873953568 at epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:50<00:00,  4.44it/s]\n",
      "  0%|          | 0/334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 11699 tn: 11992 fp: 2276 fn: 2569\n",
      "Balanced Accuracy:  0.8302144659377628  Specificity:  0.8404821979254276  AUROC Score:  0.9108602846672009  Sensitivity:  0.8199467339500981  Precision:  0.8371377459749553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [01:11<00:00,  4.68it/s]\n",
      "  0%|          | 0/223 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 11992 tn: 24323 fp: 4251 fn: 2134\n",
      "Balanced Accuracy:  0.8500797192871076  Specificity:  0.8512283894449499  AUROC Score:  0.9277654790553489  Sensitivity:  0.8489310491292652  Precision:  0.7382872622052576\n",
      "Epoch: 0/10... Loss: 0.0055... Val Loss: 0.0120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:48<00:00,  4.58it/s]\n",
      "  0%|          | 0/334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 23849 tn: 24328 fp: 4208 fn: 4687\n",
      "Balanced Accuracy:  0.8441442388561817  Specificity:  0.8525371460611157  AUROC Score:  0.9230623997130425  Sensitivity:  0.8357513316512476  Precision:  0.8500196029511352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [01:11<00:00,  4.68it/s]\n",
      "  0%|          | 0/223 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 11786 tn: 24826 fp: 3748 fn: 2340\n",
      "Balanced Accuracy:  0.8515899079489189  Specificity:  0.8688318051375377  AUROC Score:  0.9297316425367108  Sensitivity:  0.8343480107603002  Precision:  0.758722801596498\n",
      "Epoch: 1/10... Loss: 0.0047... Val Loss: 0.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:49<00:00,  4.52it/s]\n",
      "  0%|          | 0/334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 36132 tn: 36825 fp: 5979 fn: 6672\n",
      "Balanced Accuracy:  0.8522217549761705  Specificity:  0.8603167928231007  AUROC Score:  0.9297072227223033  Sensitivity:  0.8441267171292403  Precision:  0.8580180950345515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [01:11<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 11841 tn: 24816 fp: 3758 fn: 2285\n",
      "Balanced Accuracy:  0.85336168852831  Specificity:  0.8684818366347029  AUROC Score:  0.9291614336969336  Sensitivity:  0.838241540421917  Precision:  0.7590871209692929\n",
      "Epoch: 2/10... Loss: 0.0045... Val Loss: 0.0118\n",
      "Early Stop no improvement in validation loss in 1 validation steps\n",
      "\n",
      "Lowest Validation Loss: 0.01157670585732711 at epoch 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:50<00:00,  4.46it/s]\n",
      "  0%|          | 0/334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 12018 tn: 12261 fp: 2007 fn: 2250\n",
      "Balanced Accuracy:  0.8508200168208578  Specificity:  0.8593355761143818  AUROC Score:  0.9275599370777936  Sensitivity:  0.8423044575273338  Precision:  0.8568983957219252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [01:12<00:00,  4.61it/s]\n",
      "  0%|          | 0/223 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 12208 tn: 23776 fp: 4798 fn: 1918\n",
      "Balanced Accuracy:  0.848153557161025  Specificity:  0.8320851123398894  AUROC Score:  0.9252284415314416  Sensitivity:  0.8642220019821606  Precision:  0.7178642831941667\n",
      "Epoch: 0/10... Loss: 0.0050... Val Loss: 0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:49<00:00,  4.53it/s]\n",
      "  0%|          | 0/334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 24390 tn: 24862 fp: 3674 fn: 4146\n",
      "Balanced Accuracy:  0.8629800953181945  Specificity:  0.8712503504345388  AUROC Score:  0.9375982134057332  Sensitivity:  0.8547098402018503  Precision:  0.8690849486887116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [01:12<00:00,  4.59it/s]\n",
      "  0%|          | 0/223 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 12052 tn: 24618 fp: 3956 fn: 2074\n",
      "Balanced Accuracy:  0.8573654981557111  Specificity:  0.8615524602785749  AUROC Score:  0.9300817918954192  Sensitivity:  0.8531785360328472  Precision:  0.7528735632183908\n",
      "Epoch: 1/10... Loss: 0.0043... Val Loss: 0.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:49<00:00,  4.53it/s]\n",
      "  0%|          | 0/334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 36975 tn: 37655 fp: 5149 fn: 5829\n",
      "Balanced Accuracy:  0.8717643210914867  Specificity:  0.8797075039715915  AUROC Score:  0.9440810515889156  Sensitivity:  0.8638211382113821  Precision:  0.8777656442882917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [01:12<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 12092 tn: 24458 fp: 4116 fn: 2034\n",
      "Balanced Accuracy:  0.8559815791008938  Specificity:  0.855952964233219  AUROC Score:  0.9284823607698895  Sensitivity:  0.8560101939685686  Precision:  0.7460513326752222\n",
      "Epoch: 2/10... Loss: 0.0039... Val Loss: 0.0124\n",
      "Early Stop no improvement in validation loss in 1 validation steps\n",
      "\n",
      "Lowest Validation Loss: 0.011689203350167526 at epoch 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:49<00:00,  4.46it/s]\n",
      "  0%|          | 0/334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 12095 tn: 11921 fp: 2347 fn: 2173\n",
      "Balanced Accuracy:  0.8416035884496776  Specificity:  0.8355060274740679  AUROC Score:  0.9166272734821399  Sensitivity:  0.8477011494252874  Precision:  0.8374878825647417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [01:11<00:00,  4.66it/s]\n",
      "  0%|          | 0/223 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 11816 tn: 23928 fp: 4646 fn: 2310\n",
      "Balanced Accuracy:  0.8369381938975344  Specificity:  0.8374046335829776  AUROC Score:  0.9157596356466668  Sensitivity:  0.8364717542120912  Precision:  0.7177742680111773\n",
      "Epoch: 0/10... Loss: 0.0054... Val Loss: 0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:49<00:00,  4.52it/s]\n",
      "  0%|          | 0/334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 24447 tn: 24247 fp: 4289 fn: 4089\n",
      "Balanced Accuracy:  0.8532029716848892  Specificity:  0.8496986262966078  AUROC Score:  0.9272185237476922  Sensitivity:  0.8567073170731707  Precision:  0.8507447104677061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [01:11<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 12039 tn: 23389 fp: 5185 fn: 2087\n",
      "Balanced Accuracy:  0.8353997892419613  Specificity:  0.8185413312801848  AUROC Score:  0.9119934557723304  Sensitivity:  0.8522582472037378  Precision:  0.698966558290757\n",
      "Epoch: 1/10... Loss: 0.0046... Val Loss: 0.0142\n",
      "Early Stop no improvement in validation loss in 1 validation steps\n",
      "\n",
      "Lowest Validation Loss: 0.01351369211548253 at epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:49<00:00,  4.51it/s]\n",
      "  0%|          | 0/334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 12392 tn: 12393 fp: 1875 fn: 1876\n",
      "Balanced Accuracy:  0.8685520044855621  Specificity:  0.8685870479394449  AUROC Score:  0.9405333390668236  Sensitivity:  0.8685169610316793  Precision:  0.868577836966426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [01:11<00:00,  4.67it/s]\n",
      "  0%|          | 0/223 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 12435 tn: 23345 fp: 5229 fn: 1691\n",
      "Balanced Accuracy:  0.8486465653175457  Specificity:  0.8170014698677119  AUROC Score:  0.926310152898925  Sensitivity:  0.8802916607673793  Precision:  0.7039741847826086\n",
      "Epoch: 0/10... Loss: 0.0045... Val Loss: 0.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:48<00:00,  4.59it/s]\n",
      "  0%|          | 0/334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 25101 tn: 25051 fp: 3485 fn: 3435\n",
      "Balanced Accuracy:  0.8787496495654612  Specificity:  0.8778735632183908  AUROC Score:  0.9484697830573436  Sensitivity:  0.8796257359125316  Precision:  0.8780871755404743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [01:12<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 12511 tn: 23568 fp: 5006 fn: 1615\n",
      "Balanced Accuracy:  0.8552387891630884  Specificity:  0.8248057674809267  AUROC Score:  0.9295420337343077  Sensitivity:  0.8856718108452499  Precision:  0.7142204715419307\n",
      "Epoch: 1/10... Loss: 0.0039... Val Loss: 0.0131\n",
      "Early Stop no improvement in validation loss in 1 validation steps\n",
      "\n",
      "Lowest Validation Loss: 0.012964668242554916 at epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:49<00:00,  4.50it/s]\n",
      "  0%|          | 0/334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 11878 tn: 12001 fp: 2267 fn: 2390\n",
      "Balanced Accuracy:  0.836802635267732  Specificity:  0.8411129800953182  AUROC Score:  0.9173179547095927  Sensitivity:  0.8324922904401458  Precision:  0.8397313538352775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [01:11<00:00,  4.67it/s]\n",
      "  0%|          | 0/223 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 12132 tn: 24139 fp: 4435 fn: 1994\n",
      "Balanced Accuracy:  0.8518154104485403  Specificity:  0.8447889689927907  AUROC Score:  0.9294065714462308  Sensitivity:  0.85884185190429  Precision:  0.7322991489104848\n",
      "Epoch: 0/10... Loss: 0.0053... Val Loss: 0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:48<00:00,  4.56it/s]\n",
      "  0%|          | 0/334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 24171 tn: 24329 fp: 4207 fn: 4365\n",
      "Balanced Accuracy:  0.8498037566582562  Specificity:  0.8525721895149986  AUROC Score:  0.9283885417307705  Sensitivity:  0.8470353238015139  Precision:  0.8517513566847558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [01:11<00:00,  4.65it/s]\n",
      "  0%|          | 0/223 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 11757 tn: 25074 fp: 3500 fn: 2369\n",
      "Balanced Accuracy:  0.8549030413823707  Specificity:  0.8775110240078393  AUROC Score:  0.9309714764422441  Sensitivity:  0.8322950587569021  Precision:  0.770597102969129\n",
      "Epoch: 1/10... Loss: 0.0046... Val Loss: 0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:49<00:00,  4.52it/s]\n",
      "  0%|          | 0/334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 36609 tn: 36800 fp: 6004 fn: 6195\n",
      "Balanced Accuracy:  0.8575016353611813  Specificity:  0.8597327352583871  AUROC Score:  0.9342714483839911  Sensitivity:  0.8552705354639754  Precision:  0.8591040292868374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [01:13<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 12268 tn: 24069 fp: 4505 fn: 1858\n",
      "Balanced Accuracy:  0.855404339179345  Specificity:  0.8423391894729474  AUROC Score:  0.9317286617643461  Sensitivity:  0.8684694888857426  Precision:  0.7314135813509808\n",
      "Epoch: 2/10... Loss: 0.0043... Val Loss: 0.0120\n",
      "Early Stop no improvement in validation loss in 1 validation steps\n",
      "\n",
      "Lowest Validation Loss: 0.011310000168649774 at epoch 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [03:04<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  0.026626481163886287\n",
      "tp: 10019 tn: 22317 fp: 5119 fn: 1073\n",
      "Balanced Accuracy:  0.8583419685387077  Specificity:  0.8134203236623414  AUROC Score:  0.9363366756384477  Sensitivity:  0.9032636134150739  Precision:  0.661844365173735\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 27268... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "01a982fdfd06441b9d715e1c479c8e07"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>(model-0-Ensemble Test) AUROC Score</td><td>▁</td></tr><tr><td>(model-0-Ensemble Test) Balanced Accuracy</td><td>▁</td></tr><tr><td>(model-0-Ensemble Test) Precision</td><td>▁</td></tr><tr><td>(model-0-Ensemble Test) Sensitivity</td><td>▁</td></tr><tr><td>(model-0-Ensemble Test) Specificity</td><td>▁</td></tr><tr><td>(model-1) training_loss</td><td>█▂▁</td></tr><tr><td>(model-1) validation_loss</td><td>▇▁█</td></tr><tr><td>(model-1-training) AUROC Score</td><td>▁▆█</td></tr><tr><td>(model-1-training) Balanced Accuracy</td><td>▁▆█</td></tr><tr><td>(model-1-training) Precision</td><td>▁▆█</td></tr><tr><td>(model-1-training) Sensitivity</td><td>▁▆█</td></tr><tr><td>(model-1-training) Specificity</td><td>▁▆█</td></tr><tr><td>(model-1-validation) AUROC Score</td><td>▁▃█</td></tr><tr><td>(model-1-validation) Balanced Accuracy</td><td>▁▁█</td></tr><tr><td>(model-1-validation) Precision</td><td>▂█▁</td></tr><tr><td>(model-1-validation) Sensitivity</td><td>▆▁█</td></tr><tr><td>(model-1-validation) Specificity</td><td>▂█▁</td></tr><tr><td>(model-10) training_loss</td><td>█▃▁</td></tr><tr><td>(model-10) validation_loss</td><td>▇▁█</td></tr><tr><td>(model-10-training) AUROC Score</td><td>▁▆█</td></tr><tr><td>(model-10-training) Balanced Accuracy</td><td>▁▅█</td></tr><tr><td>(model-10-training) Precision</td><td>▁▅█</td></tr><tr><td>(model-10-training) Sensitivity</td><td>▁▅█</td></tr><tr><td>(model-10-training) Specificity</td><td>▁▅█</td></tr><tr><td>(model-10-validation) AUROC Score</td><td>▁▆█</td></tr><tr><td>(model-10-validation) Balanced Accuracy</td><td>▁▇█</td></tr><tr><td>(model-10-validation) Precision</td><td>▁█▁</td></tr><tr><td>(model-10-validation) Sensitivity</td><td>▆▁█</td></tr><tr><td>(model-10-validation) Specificity</td><td>▁█▁</td></tr><tr><td>(model-2) training_loss</td><td>█▁</td></tr><tr><td>(model-2) validation_loss</td><td>▁█</td></tr><tr><td>(model-2-training) AUROC Score</td><td>▁█</td></tr><tr><td>(model-2-training) Balanced Accuracy</td><td>▁█</td></tr><tr><td>(model-2-training) Precision</td><td>▁█</td></tr><tr><td>(model-2-training) Sensitivity</td><td>▁█</td></tr><tr><td>(model-2-training) Specificity</td><td>▁█</td></tr><tr><td>(model-2-validation) AUROC Score</td><td>█▁</td></tr><tr><td>(model-2-validation) Balanced Accuracy</td><td>█▁</td></tr><tr><td>(model-2-validation) Precision</td><td>▁█</td></tr><tr><td>(model-2-validation) Sensitivity</td><td>█▁</td></tr><tr><td>(model-2-validation) Specificity</td><td>▁█</td></tr><tr><td>(model-3) training_loss</td><td>█▁</td></tr><tr><td>(model-3) validation_loss</td><td>▁█</td></tr><tr><td>(model-3-training) AUROC Score</td><td>▁█</td></tr><tr><td>(model-3-training) Balanced Accuracy</td><td>▁█</td></tr><tr><td>(model-3-training) Precision</td><td>▁█</td></tr><tr><td>(model-3-training) Sensitivity</td><td>▁█</td></tr><tr><td>(model-3-training) Specificity</td><td>▁█</td></tr><tr><td>(model-3-validation) AUROC Score</td><td>▁█</td></tr><tr><td>(model-3-validation) Balanced Accuracy</td><td>▁█</td></tr><tr><td>(model-3-validation) Precision</td><td>█▁</td></tr><tr><td>(model-3-validation) Sensitivity</td><td>▁█</td></tr><tr><td>(model-3-validation) Specificity</td><td>█▁</td></tr><tr><td>(model-4) training_loss</td><td>█▁</td></tr><tr><td>(model-4) validation_loss</td><td>▁█</td></tr><tr><td>(model-4-training) AUROC Score</td><td>▁█</td></tr><tr><td>(model-4-training) Balanced Accuracy</td><td>▁█</td></tr><tr><td>(model-4-training) Precision</td><td>▁█</td></tr><tr><td>(model-4-training) Sensitivity</td><td>▁█</td></tr><tr><td>(model-4-training) Specificity</td><td>▁█</td></tr><tr><td>(model-4-validation) AUROC Score</td><td>█▁</td></tr><tr><td>(model-4-validation) Balanced Accuracy</td><td>▁█</td></tr><tr><td>(model-4-validation) Precision</td><td>█▁</td></tr><tr><td>(model-4-validation) Sensitivity</td><td>▁█</td></tr><tr><td>(model-4-validation) Specificity</td><td>█▁</td></tr><tr><td>(model-5) training_loss</td><td>█▁</td></tr><tr><td>(model-5) validation_loss</td><td>▁█</td></tr><tr><td>(model-5-training) AUROC Score</td><td>▁█</td></tr><tr><td>(model-5-training) Balanced Accuracy</td><td>▁█</td></tr><tr><td>(model-5-training) Precision</td><td>▁█</td></tr><tr><td>(model-5-training) Sensitivity</td><td>▁█</td></tr><tr><td>(model-5-training) Specificity</td><td>▁█</td></tr><tr><td>(model-5-validation) AUROC Score</td><td>█▁</td></tr><tr><td>(model-5-validation) Balanced Accuracy</td><td>█▁</td></tr><tr><td>(model-5-validation) Precision</td><td>█▁</td></tr><tr><td>(model-5-validation) Sensitivity</td><td>▁█</td></tr><tr><td>(model-5-validation) Specificity</td><td>█▁</td></tr><tr><td>(model-6) training_loss</td><td>█▃▁</td></tr><tr><td>(model-6) validation_loss</td><td>█▁▄</td></tr><tr><td>(model-6-training) AUROC Score</td><td>▁▆█</td></tr><tr><td>(model-6-training) Balanced Accuracy</td><td>▁▅█</td></tr><tr><td>(model-6-training) Precision</td><td>▁▅█</td></tr><tr><td>(model-6-training) Sensitivity</td><td>▁▆█</td></tr><tr><td>(model-6-training) Specificity</td><td>▁▅█</td></tr><tr><td>(model-6-validation) AUROC Score</td><td>▁█▆</td></tr><tr><td>(model-6-validation) Balanced Accuracy</td><td>▁▄█</td></tr><tr><td>(model-6-validation) Precision</td><td>▁██</td></tr><tr><td>(model-6-validation) Sensitivity</td><td>█▁▃</td></tr><tr><td>(model-6-validation) Specificity</td><td>▁██</td></tr><tr><td>(model-7) training_loss</td><td>█▃▁</td></tr><tr><td>(model-7) validation_loss</td><td>█▁▄</td></tr><tr><td>(model-7-training) AUROC Score</td><td>▁▅█</td></tr><tr><td>(model-7-training) Balanced Accuracy</td><td>▁▅█</td></tr><tr><td>(model-7-training) Precision</td><td>▁▅█</td></tr><tr><td>(model-7-training) Sensitivity</td><td>▁▅█</td></tr><tr><td>(model-7-training) Specificity</td><td>▁▅█</td></tr><tr><td>(model-7-validation) AUROC Score</td><td>▁█▆</td></tr><tr><td>(model-7-validation) Balanced Accuracy</td><td>▁█▇</td></tr><tr><td>(model-7-validation) Precision</td><td>▁█▇</td></tr><tr><td>(model-7-validation) Sensitivity</td><td>█▁▃</td></tr><tr><td>(model-7-validation) Specificity</td><td>▁█▇</td></tr><tr><td>(model-8) training_loss</td><td>█▁</td></tr><tr><td>(model-8) validation_loss</td><td>▁█</td></tr><tr><td>(model-8-training) AUROC Score</td><td>▁█</td></tr><tr><td>(model-8-training) Balanced Accuracy</td><td>▁█</td></tr><tr><td>(model-8-training) Precision</td><td>▁█</td></tr><tr><td>(model-8-training) Sensitivity</td><td>▁█</td></tr><tr><td>(model-8-training) Specificity</td><td>▁█</td></tr><tr><td>(model-8-validation) AUROC Score</td><td>█▁</td></tr><tr><td>(model-8-validation) Balanced Accuracy</td><td>█▁</td></tr><tr><td>(model-8-validation) Precision</td><td>█▁</td></tr><tr><td>(model-8-validation) Sensitivity</td><td>▁█</td></tr><tr><td>(model-8-validation) Specificity</td><td>█▁</td></tr><tr><td>(model-9) training_loss</td><td>█▁</td></tr><tr><td>(model-9) validation_loss</td><td>▁█</td></tr><tr><td>(model-9-training) AUROC Score</td><td>▁█</td></tr><tr><td>(model-9-training) Balanced Accuracy</td><td>▁█</td></tr><tr><td>(model-9-training) Precision</td><td>▁█</td></tr><tr><td>(model-9-training) Sensitivity</td><td>▁█</td></tr><tr><td>(model-9-training) Specificity</td><td>▁█</td></tr><tr><td>(model-9-validation) AUROC Score</td><td>▁█</td></tr><tr><td>(model-9-validation) Balanced Accuracy</td><td>▁█</td></tr><tr><td>(model-9-validation) Precision</td><td>▁█</td></tr><tr><td>(model-9-validation) Sensitivity</td><td>▁█</td></tr><tr><td>(model-9-validation) Specificity</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>(model-0-Ensemble Test) AUROC Score</td><td>0.93634</td></tr><tr><td>(model-0-Ensemble Test) Balanced Accuracy</td><td>0.85834</td></tr><tr><td>(model-0-Ensemble Test) Precision</td><td>0.66184</td></tr><tr><td>(model-0-Ensemble Test) Sensitivity</td><td>0.90326</td></tr><tr><td>(model-0-Ensemble Test) Specificity</td><td>0.81342</td></tr><tr><td>(model-1) training_loss</td><td>0.0041</td></tr><tr><td>(model-1) validation_loss</td><td>0.01379</td></tr><tr><td>(model-1-training) AUROC Score</td><td>0.94219</td></tr><tr><td>(model-1-training) Balanced Accuracy</td><td>0.86995</td></tr><tr><td>(model-1-training) Precision</td><td>0.86958</td></tr><tr><td>(model-1-training) Sensitivity</td><td>0.87046</td></tr><tr><td>(model-1-training) Specificity</td><td>0.86945</td></tr><tr><td>(model-1-validation) AUROC Score</td><td>0.92234</td></tr><tr><td>(model-1-validation) Balanced Accuracy</td><td>0.84472</td></tr><tr><td>(model-1-validation) Precision</td><td>0.69154</td></tr><tr><td>(model-1-validation) Sensitivity</td><td>0.88447</td></tr><tr><td>(model-1-validation) Specificity</td><td>0.80496</td></tr><tr><td>(model-10) training_loss</td><td>0.00434</td></tr><tr><td>(model-10) validation_loss</td><td>0.01196</td></tr><tr><td>(model-10-training) AUROC Score</td><td>0.93427</td></tr><tr><td>(model-10-training) Balanced Accuracy</td><td>0.8575</td></tr><tr><td>(model-10-training) Precision</td><td>0.8591</td></tr><tr><td>(model-10-training) Sensitivity</td><td>0.85527</td></tr><tr><td>(model-10-training) Specificity</td><td>0.85973</td></tr><tr><td>(model-10-validation) AUROC Score</td><td>0.93173</td></tr><tr><td>(model-10-validation) Balanced Accuracy</td><td>0.8554</td></tr><tr><td>(model-10-validation) Precision</td><td>0.73141</td></tr><tr><td>(model-10-validation) Sensitivity</td><td>0.86847</td></tr><tr><td>(model-10-validation) Specificity</td><td>0.84234</td></tr><tr><td>(model-2) training_loss</td><td>0.00444</td></tr><tr><td>(model-2) validation_loss</td><td>0.01181</td></tr><tr><td>(model-2-training) AUROC Score</td><td>0.93221</td></tr><tr><td>(model-2-training) Balanced Accuracy</td><td>0.85709</td></tr><tr><td>(model-2-training) Precision</td><td>0.86142</td></tr><tr><td>(model-2-training) Sensitivity</td><td>0.8511</td></tr><tr><td>(model-2-training) Specificity</td><td>0.86309</td></tr><tr><td>(model-2-validation) AUROC Score</td><td>0.92448</td></tr><tr><td>(model-2-validation) Balanced Accuracy</td><td>0.84463</td></tr><tr><td>(model-2-validation) Precision</td><td>0.7648</td></tr><tr><td>(model-2-validation) Sensitivity</td><td>0.81283</td></tr><tr><td>(model-2-validation) Specificity</td><td>0.87643</td></tr><tr><td>(model-3) training_loss</td><td>0.00449</td></tr><tr><td>(model-3) validation_loss</td><td>0.01267</td></tr><tr><td>(model-3-training) AUROC Score</td><td>0.93024</td></tr><tr><td>(model-3-training) Balanced Accuracy</td><td>0.85241</td></tr><tr><td>(model-3-training) Precision</td><td>0.85426</td></tr><tr><td>(model-3-training) Sensitivity</td><td>0.8498</td></tr><tr><td>(model-3-training) Specificity</td><td>0.85503</td></tr><tr><td>(model-3-validation) AUROC Score</td><td>0.92934</td></tr><tr><td>(model-3-validation) Balanced Accuracy</td><td>0.85449</td></tr><tr><td>(model-3-validation) Precision</td><td>0.72652</td></tr><tr><td>(model-3-validation) Sensitivity</td><td>0.87109</td></tr><tr><td>(model-3-validation) Specificity</td><td>0.83789</td></tr><tr><td>(model-4) training_loss</td><td>0.00498</td></tr><tr><td>(model-4) validation_loss</td><td>0.01181</td></tr><tr><td>(model-4-training) AUROC Score</td><td>0.91716</td></tr><tr><td>(model-4-training) Balanced Accuracy</td><td>0.83806</td></tr><tr><td>(model-4-training) Precision</td><td>0.83964</td></tr><tr><td>(model-4-training) Sensitivity</td><td>0.83575</td></tr><tr><td>(model-4-training) Specificity</td><td>0.84038</td></tr><tr><td>(model-4-validation) AUROC Score</td><td>0.93061</td></tr><tr><td>(model-4-validation) Balanced Accuracy</td><td>0.85488</td></tr><tr><td>(model-4-validation) Precision</td><td>0.74994</td></tr><tr><td>(model-4-validation) Sensitivity</td><td>0.84985</td></tr><tr><td>(model-4-validation) Specificity</td><td>0.85991</td></tr><tr><td>(model-5) training_loss</td><td>0.00421</td></tr><tr><td>(model-5) validation_loss</td><td>0.01252</td></tr><tr><td>(model-5-training) AUROC Score</td><td>0.93896</td></tr><tr><td>(model-5-training) Balanced Accuracy</td><td>0.86682</td></tr><tr><td>(model-5-training) Precision</td><td>0.86573</td></tr><tr><td>(model-5-training) Sensitivity</td><td>0.86831</td></tr><tr><td>(model-5-training) Specificity</td><td>0.86533</td></tr><tr><td>(model-5-validation) AUROC Score</td><td>0.92872</td></tr><tr><td>(model-5-validation) Balanced Accuracy</td><td>0.85423</td></tr><tr><td>(model-5-validation) Precision</td><td>0.71705</td></tr><tr><td>(model-5-validation) Sensitivity</td><td>0.88015</td></tr><tr><td>(model-5-validation) Specificity</td><td>0.82831</td></tr><tr><td>(model-6) training_loss</td><td>0.00445</td></tr><tr><td>(model-6) validation_loss</td><td>0.01177</td></tr><tr><td>(model-6-training) AUROC Score</td><td>0.92971</td></tr><tr><td>(model-6-training) Balanced Accuracy</td><td>0.85222</td></tr><tr><td>(model-6-training) Precision</td><td>0.85802</td></tr><tr><td>(model-6-training) Sensitivity</td><td>0.84413</td></tr><tr><td>(model-6-training) Specificity</td><td>0.86032</td></tr><tr><td>(model-6-validation) AUROC Score</td><td>0.92916</td></tr><tr><td>(model-6-validation) Balanced Accuracy</td><td>0.85336</td></tr><tr><td>(model-6-validation) Precision</td><td>0.75909</td></tr><tr><td>(model-6-validation) Sensitivity</td><td>0.83824</td></tr><tr><td>(model-6-validation) Specificity</td><td>0.86848</td></tr><tr><td>(model-7) training_loss</td><td>0.00389</td></tr><tr><td>(model-7) validation_loss</td><td>0.01236</td></tr><tr><td>(model-7-training) AUROC Score</td><td>0.94408</td></tr><tr><td>(model-7-training) Balanced Accuracy</td><td>0.87176</td></tr><tr><td>(model-7-training) Precision</td><td>0.87777</td></tr><tr><td>(model-7-training) Sensitivity</td><td>0.86382</td></tr><tr><td>(model-7-training) Specificity</td><td>0.87971</td></tr><tr><td>(model-7-validation) AUROC Score</td><td>0.92848</td></tr><tr><td>(model-7-validation) Balanced Accuracy</td><td>0.85598</td></tr><tr><td>(model-7-validation) Precision</td><td>0.74605</td></tr><tr><td>(model-7-validation) Sensitivity</td><td>0.85601</td></tr><tr><td>(model-7-validation) Specificity</td><td>0.85595</td></tr><tr><td>(model-8) training_loss</td><td>0.00465</td></tr><tr><td>(model-8) validation_loss</td><td>0.01419</td></tr><tr><td>(model-8-training) AUROC Score</td><td>0.92722</td></tr><tr><td>(model-8-training) Balanced Accuracy</td><td>0.8532</td></tr><tr><td>(model-8-training) Precision</td><td>0.85074</td></tr><tr><td>(model-8-training) Sensitivity</td><td>0.85671</td></tr><tr><td>(model-8-training) Specificity</td><td>0.8497</td></tr><tr><td>(model-8-validation) AUROC Score</td><td>0.91199</td></tr><tr><td>(model-8-validation) Balanced Accuracy</td><td>0.8354</td></tr><tr><td>(model-8-validation) Precision</td><td>0.69897</td></tr><tr><td>(model-8-validation) Sensitivity</td><td>0.85226</td></tr><tr><td>(model-8-validation) Specificity</td><td>0.81854</td></tr><tr><td>(model-9) training_loss</td><td>0.0039</td></tr><tr><td>(model-9) validation_loss</td><td>0.01305</td></tr><tr><td>(model-9-training) AUROC Score</td><td>0.94847</td></tr><tr><td>(model-9-training) Balanced Accuracy</td><td>0.87875</td></tr><tr><td>(model-9-training) Precision</td><td>0.87809</td></tr><tr><td>(model-9-training) Sensitivity</td><td>0.87963</td></tr><tr><td>(model-9-training) Specificity</td><td>0.87787</td></tr><tr><td>(model-9-validation) AUROC Score</td><td>0.92954</td></tr><tr><td>(model-9-validation) Balanced Accuracy</td><td>0.85524</td></tr><tr><td>(model-9-validation) Precision</td><td>0.71422</td></tr><tr><td>(model-9-validation) Sensitivity</td><td>0.88567</td></tr><tr><td>(model-9-validation) Specificity</td><td>0.82481</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">treasured-sky-46</strong>: <a href=\"https://wandb.ai/ece9603_project/breast-histopathology-classification/runs/2xffr30x\" target=\"_blank\">https://wandb.ai/ece9603_project/breast-histopathology-classification/runs/2xffr30x</a><br/>\nFind logs at: <code>.\\wandb\\run-20211125_210333-2xffr30x\\logs</code><br/>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the sweep\n",
    "#wandb.agent(sweep_id, trainAndTestModel)\n",
    "\n",
    "trainAndTestModel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}